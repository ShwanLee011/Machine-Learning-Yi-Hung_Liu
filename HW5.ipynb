{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "import time\n",
        "def SFS(features, labels, Names):\n",
        "  Ns = features.shape[1]\n",
        "  feature_selected = []\n",
        "  accs = []\n",
        "  best_acc = 0\n",
        "  best_loc = 0\n",
        "  LDA = LinearDiscriminantAnalysis()\n",
        "  t_0 = time.time()\n",
        "  for i in range(Ns):\n",
        "    remaining = [feature for feature in range(Ns) if feature not in feature_selected]\n",
        "    best_features_now  = None\n",
        "    best_acc_now = 0\n",
        "    feature_Combination = []\n",
        "    for feat in remaining:\n",
        "      curr_features = feature_selected + [feat]\n",
        "      curr_features = [fea for fea in curr_features if fea is not None]\n",
        "      x1,x2,y1,y2 = train_test_split(features[:, np.array(curr_features).astype(int)], labels, test_size = 0.5,random_state = 0)\n",
        "      LDA.fit(x1,y1)\n",
        "      acc1 = LDA.score(x2,y2)*100\n",
        "      LDA.fit(x2,y2)\n",
        "      acc2 = LDA.score(x1,y1)*100\n",
        "      avg = 0.5*(acc1+acc2)\n",
        "      if avg > best_acc_now:\n",
        "        best_acc_now = avg\n",
        "        best_features_now = feat\n",
        "    if best_features_now is not None:\n",
        "      feature_selected.append(best_features_now)\n",
        "      accs.append(best_acc_now)\n",
        "    if best_acc_now > best_acc:\n",
        "      best_acc = best_acc_now\n",
        "      best_loc = i\n",
        "    print(f'Step no. {i+1}: Feature selected now {best_features_now}. Feature name: {Name[best_features_now]}')\n",
        "    print('Associated accuracy = {:.2f}%'.format(best_acc_now))\n",
        "  t_f = time.time()\n",
        "  print(\"Best accuracy is: {:.2f}%\" .format(best_acc))\n",
        "  print(\"Features that have best accuracy (indices)\", feature_selected[:best_loc])\n",
        "  print(\"Time cost is {:.4f} sec(s).\".format(t_f-t_0))\n",
        "#Main starts\n",
        "cancer = load_breast_cancer()\n",
        "features = cancer.data\n",
        "labels = cancer.target\n",
        "Name = cancer.feature_names\n",
        "SFS(features, labels, Name)"
      ],
      "metadata": {
        "id": "xy_gpFVlvjpC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79b31339-bec8-4376-ce03-eeb4013c43ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step no. 1: Feature selected now 27. Feature name: worst concave points\n",
            "Associated accuracy = 91.04%\n",
            "Step no. 2: Feature selected now 20. Feature name: worst radius\n",
            "Associated accuracy = 94.02%\n",
            "Step no. 3: Feature selected now 1. Feature name: mean texture\n",
            "Associated accuracy = 95.61%\n",
            "Step no. 4: Feature selected now 21. Feature name: worst texture\n",
            "Associated accuracy = 95.61%\n",
            "Step no. 5: Feature selected now 23. Feature name: worst area\n",
            "Associated accuracy = 96.49%\n",
            "Step no. 6: Feature selected now 14. Feature name: smoothness error\n",
            "Associated accuracy = 96.84%\n",
            "Step no. 7: Feature selected now 28. Feature name: worst symmetry\n",
            "Associated accuracy = 97.01%\n",
            "Step no. 8: Feature selected now 15. Feature name: compactness error\n",
            "Associated accuracy = 97.36%\n",
            "Step no. 9: Feature selected now 3. Feature name: mean area\n",
            "Associated accuracy = 97.54%\n",
            "Step no. 10: Feature selected now 17. Feature name: concave points error\n",
            "Associated accuracy = 97.54%\n",
            "Step no. 11: Feature selected now 5. Feature name: mean compactness\n",
            "Associated accuracy = 97.54%\n",
            "Step no. 12: Feature selected now 26. Feature name: worst concavity\n",
            "Associated accuracy = 97.54%\n",
            "Step no. 13: Feature selected now 11. Feature name: texture error\n",
            "Associated accuracy = 97.54%\n",
            "Step no. 14: Feature selected now 13. Feature name: area error\n",
            "Associated accuracy = 97.36%\n",
            "Step no. 15: Feature selected now 22. Feature name: worst perimeter\n",
            "Associated accuracy = 97.19%\n",
            "Step no. 16: Feature selected now 4. Feature name: mean smoothness\n",
            "Associated accuracy = 97.01%\n",
            "Step no. 17: Feature selected now 24. Feature name: worst smoothness\n",
            "Associated accuracy = 96.66%\n",
            "Step no. 18: Feature selected now 7. Feature name: mean concave points\n",
            "Associated accuracy = 96.84%\n",
            "Step no. 19: Feature selected now 6. Feature name: mean concavity\n",
            "Associated accuracy = 96.48%\n",
            "Step no. 20: Feature selected now 18. Feature name: symmetry error\n",
            "Associated accuracy = 96.31%\n",
            "Step no. 21: Feature selected now 16. Feature name: concavity error\n",
            "Associated accuracy = 96.13%\n",
            "Step no. 22: Feature selected now 2. Feature name: mean perimeter\n",
            "Associated accuracy = 95.78%\n",
            "Step no. 23: Feature selected now 10. Feature name: radius error\n",
            "Associated accuracy = 95.60%\n",
            "Step no. 24: Feature selected now 8. Feature name: mean symmetry\n",
            "Associated accuracy = 95.61%\n",
            "Step no. 25: Feature selected now 0. Feature name: mean radius\n",
            "Associated accuracy = 95.43%\n",
            "Step no. 26: Feature selected now 9. Feature name: mean fractal dimension\n",
            "Associated accuracy = 95.43%\n",
            "Step no. 27: Feature selected now 19. Feature name: fractal dimension error\n",
            "Associated accuracy = 95.43%\n",
            "Step no. 28: Feature selected now 29. Feature name: worst fractal dimension\n",
            "Associated accuracy = 95.43%\n",
            "Step no. 29: Feature selected now 25. Feature name: worst compactness\n",
            "Associated accuracy = 95.43%\n",
            "Step no. 30: Feature selected now 12. Feature name: perimeter error\n",
            "Associated accuracy = 95.08%\n",
            "Best accuracy is: 97.54%\n",
            "Features that have best accuracy (indices) [27, 20, 1, 21, 23, 14, 28, 15]\n",
            "Time cost is 2.6236 sec(s).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "def Fisher_with_2fold(features,labels, Names, d=30):\n",
        "  class1_len = len(features[labels == 1])\n",
        "  class0_len = len(features[labels == 0])\n",
        "  t_0 = time.time()\n",
        "  mean_vec = []\n",
        "  for i in np.unique(labels):\n",
        "    mean_vec.append(np.mean(features[labels == i], axis = 0))\n",
        "  mean = np.mean(mean_vec, axis = 0)\n",
        "  Sw = np.zeros((d, d))\n",
        "  for ix in np.unique(labels):\n",
        "    x = features[labels == ix]\n",
        "    for j in range(len(x)):\n",
        "      temp = x[j, :] - mean_vec[ix]\n",
        "      Sw += np.outer(temp,temp)\n",
        "  Sb = np.zeros((d, d))\n",
        "  for i in np.unique(labels):\n",
        "      Sb += len(features[labels==i])*(mean_vec[i] - mean)@ (mean_vec[i] - mean).T\n",
        "      Fscore = np.diag(np.linalg.inv(Sw) @ Sb)\n",
        "      aftersort = np.argsort(Fscore)[::-1]\n",
        "      top_d_feature = aftersort[:d]\n",
        "      top_dscore = Fscore[top_d_feature]\n",
        "  best_acc = 0\n",
        "  best_features = None\n",
        "  LDA = LinearDiscriminantAnalysis()\n",
        "  for ix in range(1, min(d, top_d_feature.shape[0]) + 1):\n",
        "    feature_selected = features[:, top_d_feature[:ix]]\n",
        "    x1,x2,y1,y2 = train_test_split(feature_selected, labels, test_size = 0.5, random_state = 0)\n",
        "    LDA.fit(x1,y1)\n",
        "    acc1 = LDA.score(x2,y2)*100\n",
        "    LDA.fit(x2,y2)\n",
        "    acc2 = LDA.score(x1,y1)*100\n",
        "    acc = (acc1+acc2)/2\n",
        "    print(f'Top {ix} features, Selected feature now is {top_d_feature[ix-1]}')\n",
        "    print(f'Feature name:{Names[top_d_feature[ix-1]]}')\n",
        "    print(\"associated accuracy is: {:.2f}%\".format(acc))\n",
        "    if acc> best_acc:\n",
        "      best_acc = acc\n",
        "      best_features = feature_selected\n",
        "  t_f = time.time()\n",
        "  print(\"Best accuracy is: {:.2f}%\".format(best_acc))\n",
        "  print(\"Selected Features that have best accuracy:\", top_d_feature[: best_features.shape[1]])\n",
        "  print(\"Time cost is: {:.4f} sec(s).\".format(t_f-t_0))\n",
        "  return top_d_feature, top_dscore\n",
        "cancer = load_breast_cancer()\n",
        "features = cancer.data\n",
        "labels = cancer.target\n",
        "Fisher_with_2fold(features, labels, Name)"
      ],
      "metadata": {
        "id": "cQZMHvkALjel",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc5c2569-d7f9-4bac-bed0-4a231e9b38ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 1 features, Selected feature now is 19\n",
            "Feature name:fractal dimension error\n",
            "associated accuracy is: 61.68%\n",
            "Top 2 features, Selected feature now is 14\n",
            "Feature name:smoothness error\n",
            "associated accuracy is: 61.51%\n",
            "Top 3 features, Selected feature now is 17\n",
            "Feature name:concave points error\n",
            "associated accuracy is: 73.11%\n",
            "Top 4 features, Selected feature now is 9\n",
            "Feature name:mean fractal dimension\n",
            "associated accuracy is: 72.23%\n",
            "Top 5 features, Selected feature now is 4\n",
            "Feature name:mean smoothness\n",
            "associated accuracy is: 81.19%\n",
            "Top 6 features, Selected feature now is 7\n",
            "Feature name:mean concave points\n",
            "associated accuracy is: 90.16%\n",
            "Top 7 features, Selected feature now is 18\n",
            "Feature name:symmetry error\n",
            "associated accuracy is: 89.63%\n",
            "Top 8 features, Selected feature now is 25\n",
            "Feature name:worst compactness\n",
            "associated accuracy is: 92.62%\n",
            "Top 9 features, Selected feature now is 26\n",
            "Feature name:worst concavity\n",
            "associated accuracy is: 92.27%\n",
            "Top 10 features, Selected feature now is 28\n",
            "Feature name:worst symmetry\n",
            "associated accuracy is: 94.03%\n",
            "Top 11 features, Selected feature now is 20\n",
            "Feature name:worst radius\n",
            "associated accuracy is: 94.03%\n",
            "Top 12 features, Selected feature now is 12\n",
            "Feature name:perimeter error\n",
            "associated accuracy is: 93.85%\n",
            "Top 13 features, Selected feature now is 21\n",
            "Feature name:worst texture\n",
            "associated accuracy is: 95.78%\n",
            "Top 14 features, Selected feature now is 8\n",
            "Feature name:mean symmetry\n",
            "associated accuracy is: 95.08%\n",
            "Top 15 features, Selected feature now is 13\n",
            "Feature name:area error\n",
            "associated accuracy is: 95.43%\n",
            "Top 16 features, Selected feature now is 3\n",
            "Feature name:mean area\n",
            "associated accuracy is: 95.43%\n",
            "Top 17 features, Selected feature now is 23\n",
            "Feature name:worst area\n",
            "associated accuracy is: 95.78%\n",
            "Top 18 features, Selected feature now is 22\n",
            "Feature name:worst perimeter\n",
            "associated accuracy is: 95.43%\n",
            "Top 19 features, Selected feature now is 2\n",
            "Feature name:mean perimeter\n",
            "associated accuracy is: 95.08%\n",
            "Top 20 features, Selected feature now is 1\n",
            "Feature name:mean texture\n",
            "associated accuracy is: 95.25%\n",
            "Top 21 features, Selected feature now is 0\n",
            "Feature name:mean radius\n",
            "associated accuracy is: 95.25%\n",
            "Top 22 features, Selected feature now is 11\n",
            "Feature name:texture error\n",
            "associated accuracy is: 95.25%\n",
            "Top 23 features, Selected feature now is 6\n",
            "Feature name:mean concavity\n",
            "associated accuracy is: 95.08%\n",
            "Top 24 features, Selected feature now is 10\n",
            "Feature name:radius error\n",
            "associated accuracy is: 95.08%\n",
            "Top 25 features, Selected feature now is 5\n",
            "Feature name:mean compactness\n",
            "associated accuracy is: 94.90%\n",
            "Top 26 features, Selected feature now is 27\n",
            "Feature name:worst concave points\n",
            "associated accuracy is: 94.90%\n",
            "Top 27 features, Selected feature now is 24\n",
            "Feature name:worst smoothness\n",
            "associated accuracy is: 94.73%\n",
            "Top 28 features, Selected feature now is 16\n",
            "Feature name:concavity error\n",
            "associated accuracy is: 94.90%\n",
            "Top 29 features, Selected feature now is 15\n",
            "Feature name:compactness error\n",
            "associated accuracy is: 94.90%\n",
            "Top 30 features, Selected feature now is 29\n",
            "Feature name:worst fractal dimension\n",
            "associated accuracy is: 95.08%\n",
            "Best accuracy is: 95.78%\n",
            "Selected Features that have best accuracy: [19 14 17  9  4  7 18 25 26 28 20 12 21]\n",
            "Time cost is: 0.2359 sec(s).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([19, 14, 17,  9,  4,  7, 18, 25, 26, 28, 20, 12, 21,  8, 13,  3, 23,\n",
              "        22,  2,  1,  0, 11,  6, 10,  5, 27, 24, 16, 15, 29]),\n",
              " array([ 2.57041921e+11,  7.64530593e+10,  4.47200008e+10,  3.71724601e+10,\n",
              "         5.46423160e+09,  4.11685775e+09,  4.09204119e+09,  3.93498890e+09,\n",
              "         2.35713882e+09,  5.35530335e+08,  2.87341208e+08,  6.20930204e+07,\n",
              "         4.21002620e+07,  1.84279654e+07,  9.43408346e+06,  9.03891645e+05,\n",
              "        -1.47378883e+06, -3.61732437e+06, -1.93278954e+07, -3.83844556e+07,\n",
              "        -5.47301524e+07, -2.31242194e+08, -2.08195417e+09, -2.14433227e+09,\n",
              "        -4.42511433e+09, -4.86850836e+09, -9.11017993e+09, -1.17783088e+10,\n",
              "        -3.25614773e+10, -3.61256980e+10]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "\n",
        "import time\n",
        "\n",
        "# SFS\n",
        "def sequential_forward_selection_2fold(X, y):\n",
        "\n",
        "    print(\"------------------------SFS-----------------------------\")\n",
        "\n",
        "    num_features = X.shape[1]\n",
        "    selected_features = []\n",
        "    accuracies = []\n",
        "    best_accuracy = 0\n",
        "    best_loc = 0\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i in range(num_features):   # 30\n",
        "        remaining_features = [feature for feature in range(num_features) if feature not in selected_features]\n",
        "        local_best_feature = None\n",
        "        local_best_accuracy = 0\n",
        "\n",
        "        for feature in remaining_features:\n",
        "            current_features = selected_features + [feature]\n",
        "\n",
        "            # Split the data into two folds for each iteration\n",
        "            current_features = [feature for feature in current_features if feature is not None]\n",
        "            fold1_X, fold2_X, fold1_y, fold2_y = train_test_split(X[:, np.array(current_features).astype(int)], y, test_size=0.5, random_state=0)\n",
        "\n",
        "            # Initialize LDA\n",
        "            lda_ = LDA()\n",
        "\n",
        "            # Fit and evaluate the model on the first fold\n",
        "            lda_.fit(fold1_X, fold1_y)\n",
        "            fold_1_accuracy = lda_.score(fold2_X, fold2_y) * 100\n",
        "\n",
        "            # Fit and evaluate the model on the second fold\n",
        "            lda_.fit(fold2_X, fold2_y)\n",
        "            fold_2_accuracy = lda_.score(fold1_X, fold1_y) * 100\n",
        "\n",
        "            # Calculate the average accuracy\n",
        "            accuracy = (fold_1_accuracy + fold_2_accuracy) / 2\n",
        "\n",
        "            if accuracy > local_best_accuracy:\n",
        "                local_best_accuracy = accuracy\n",
        "                local_best_feature = feature\n",
        "\n",
        "        if local_best_feature is not None:\n",
        "            selected_features.append(local_best_feature)\n",
        "            accuracies.append(local_best_accuracy)\n",
        "\n",
        "        if local_best_accuracy > best_accuracy:\n",
        "            best_accuracy = local_best_accuracy\n",
        "            best_loc = i\n",
        "\n",
        "        print(f\" Step {i + 1}: Selected Feature {local_best_feature}, Accuracy: {local_best_accuracy}\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    execution_time = end_time - start_time\n",
        "    print(f\"time cost = {execution_time} seconds\")\n",
        "\n",
        "    print(\" [-] Best Accuracy:\", best_accuracy)\n",
        "    print(\" [-] Features with the highest accuracy (indices):\", selected_features[:best_loc])\n",
        "\n",
        "    return selected_features, accuracies\n",
        "\n",
        "\n",
        "def fisher_criterion_2fold(X, y, k=30):\n",
        "\n",
        "    print(\"------------------------Fisher's Criterion-----------------------------\")\n",
        "\n",
        "    pos_len = len(X[y == 1])\n",
        "    neg_len = len(X[y == 0])\n",
        "    data_len = (pos_len + neg_len)\n",
        "\n",
        "    # find the mean vector for each class\n",
        "    mean_vectors = []\n",
        "    for i in np.unique(y):\n",
        "        mean_vectors.append(np.mean(X[y == i], axis=0))\n",
        "\n",
        "    mean = np.mean(mean_vectors, axis=0)\n",
        "\n",
        "    # find the within-class matrix (Sw)\n",
        "    Sw = np.zeros((X.shape[1], X.shape[1]))\n",
        "    for i in np.unique(y):\n",
        "        class_samples = X[y == i]\n",
        "        for j in range(len(class_samples)):\n",
        "            diff = class_samples[j, :] - mean_vectors[i]\n",
        "            Sw += np.outer(diff, diff)\n",
        "\n",
        "    # find the Between-class matrix (Sb)\n",
        "    Sb = np.zeros((X.shape[1], X.shape[1]))\n",
        "    for i in np.unique(y):\n",
        "        Sb += len(X[y == i]) * (mean_vectors[i] - mean) @ (mean_vectors[i] - mean).T\n",
        "\n",
        "        # calculate Fisher's scores\n",
        "        F_scores = np.diag(np.linalg.inv(Sw) @ Sb)\n",
        "\n",
        "        # sort indices based on F-scores in descending order\n",
        "        sorted_indices = np.argsort(F_scores)[::-1]\n",
        "\n",
        "        # get top k indices and their corresponding F-scores\n",
        "        top_k_indices = sorted_indices[:k]\n",
        "        top_k_scores = F_scores[top_k_indices]\n",
        "\n",
        "        # print top k indices and their corresponding F-scores\n",
        "        # print(f\"Top {k} indices: {top_k_indices}\")\n",
        "\n",
        "    # Initialize variables to store information about the best accuracy\n",
        "    best_accuracy = 0\n",
        "    best_selected_features = None\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Loop through the top k features\n",
        "    for i in range(1, min(k, len(top_k_indices)) + 1):\n",
        "        selected_features = X[:, top_k_indices[:i]]\n",
        "\n",
        "        # Split the data into two folds for each iteration\n",
        "        fold1_X, fold2_X, fold1_y, fold2_y = train_test_split(selected_features, y, test_size=0.5, random_state=0)\n",
        "\n",
        "        # Initialize LDA\n",
        "        lda_ = LDA()\n",
        "\n",
        "        # Fit and evaluate the model on the first fold\n",
        "        lda_.fit(fold1_X, fold1_y)\n",
        "        fold_1_accuracy = lda_.score(fold2_X, fold2_y) * 100\n",
        "\n",
        "        # Fit and evaluate the model on the second fold\n",
        "        lda_.fit(fold2_X, fold2_y)\n",
        "        fold_2_accuracy = lda_.score(fold1_X, fold1_y) * 100\n",
        "\n",
        "        accuracy = (fold_1_accuracy + fold_2_accuracy) / 2\n",
        "\n",
        "        print(f\" Top {i} features, Selected Feature = {top_k_indices[i-1]},  Accuracy: {accuracy}\")\n",
        "\n",
        "        # Update the best accuracy and selected features if a new best is found\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            best_selected_features = selected_features\n",
        "\n",
        "    end_time = time.time()\n",
        "    execution_time = end_time - start_time\n",
        "    print(f\"time cost = {execution_time} seconds\")\n",
        "\n",
        "    # Print the best accuracy and corresponding features\n",
        "    print(\" [-] Best Accuracy:\", best_accuracy)\n",
        "    print(\" [-] Selected Features for Best Accuracy:\", top_k_indices[:best_selected_features.shape[1]])\n",
        "\n",
        "\n",
        "    return top_k_indices, top_k_scores\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    cancer = load_breast_cancer()\n",
        "    x = cancer.data\n",
        "    y = cancer.target\n",
        "\n",
        "    sequential_forward_selection_2fold(x, y)\n",
        "    fisher_criterion_2fold(x, y)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ut_Em32t9cN",
        "outputId": "c6069d9e-d08d-49db-e555-77a33c451bca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------SFS-----------------------------\n",
            " Step 1: Selected Feature 27, Accuracy: 91.03904126513467\n",
            " Step 2: Selected Feature 20, Accuracy: 94.02458611317024\n",
            " Step 3: Selected Feature 1, Accuracy: 95.60723993081295\n",
            " Step 4: Selected Feature 21, Accuracy: 95.60723993081295\n",
            " Step 5: Selected Feature 23, Accuracy: 96.48566839634297\n",
            " Step 6: Selected Feature 14, Accuracy: 96.83654558932542\n",
            " Step 7: Selected Feature 28, Accuracy: 97.01198418581666\n",
            " Step 8: Selected Feature 15, Accuracy: 97.364096861873\n",
            " Step 9: Selected Feature 3, Accuracy: 97.53953545836421\n",
            " Step 10: Selected Feature 17, Accuracy: 97.53953545836421\n",
            " Step 11: Selected Feature 5, Accuracy: 97.53953545836421\n",
            " Step 12: Selected Feature 26, Accuracy: 97.53891771682729\n",
            " Step 13: Selected Feature 11, Accuracy: 97.53891771682729\n",
            " Step 14: Selected Feature 13, Accuracy: 97.36347912033605\n",
            " Step 15: Selected Feature 22, Accuracy: 97.18804052384482\n",
            " Step 16: Selected Feature 4, Accuracy: 97.01198418581666\n",
            " Step 17: Selected Feature 24, Accuracy: 96.65987150976032\n",
            " Step 18: Selected Feature 7, Accuracy: 96.83654558932542\n",
            " Step 19: Selected Feature 6, Accuracy: 96.48443291326909\n",
            " Step 20: Selected Feature 18, Accuracy: 96.3096120583148\n",
            " Step 21: Selected Feature 16, Accuracy: 96.13293797874968\n",
            " Step 22: Selected Feature 2, Accuracy: 95.78082530269336\n",
            " Step 23: Selected Feature 10, Accuracy: 95.60476896466518\n",
            " Step 24: Selected Feature 8, Accuracy: 95.60538670620213\n",
            " Step 25: Selected Feature 0, Accuracy: 95.42933036817396\n",
            " Step 26: Selected Feature 9, Accuracy: 95.42933036817396\n",
            " Step 27: Selected Feature 19, Accuracy: 95.42933036817396\n",
            " Step 28: Selected Feature 29, Accuracy: 95.42871262663701\n",
            " Step 29: Selected Feature 25, Accuracy: 95.42871262663701\n",
            " Step 30: Selected Feature 12, Accuracy: 95.07783543365456\n",
            "time cost = 4.515224456787109 seconds\n",
            " [-] Best Accuracy: 97.53953545836421\n",
            " [-] Features with the highest accuracy (indices): [27, 20, 1, 21, 23, 14, 28, 15]\n",
            "------------------------Fisher's Criterion-----------------------------\n",
            " Top 1 features, Selected Feature = 19,  Accuracy: 61.68211020509019\n",
            " Top 2 features, Selected Feature = 14,  Accuracy: 61.50605386706202\n",
            " Top 3 features, Selected Feature = 17,  Accuracy: 73.10600444773907\n",
            " Top 4 features, Selected Feature = 9,  Accuracy: 72.22757598220903\n",
            " Top 5 features, Selected Feature = 4,  Accuracy: 81.19471213244378\n",
            " Top 6 features, Selected Feature = 7,  Accuracy: 90.16061279960465\n",
            " Top 7 features, Selected Feature = 18,  Accuracy: 89.63182604398321\n",
            " Top 8 features, Selected Feature = 25,  Accuracy: 92.61984185816654\n",
            " Top 9 features, Selected Feature = 26,  Accuracy: 92.26896466518409\n",
            " Top 10 features, Selected Feature = 28,  Accuracy: 94.02705707931801\n",
            " Top 11 features, Selected Feature = 20,  Accuracy: 94.02582159624413\n",
            " Top 12 features, Selected Feature = 12,  Accuracy: 93.84976525821597\n",
            " Top 13 features, Selected Feature = 21,  Accuracy: 95.78267852730417\n",
            " Top 14 features, Selected Feature = 8,  Accuracy: 95.07907091672844\n",
            " Top 15 features, Selected Feature = 13,  Accuracy: 95.42933036817396\n",
            " Top 16 features, Selected Feature = 3,  Accuracy: 95.42994810971089\n",
            " Top 17 features, Selected Feature = 23,  Accuracy: 95.78144304423029\n",
            " Top 18 features, Selected Feature = 22,  Accuracy: 95.42994810971089\n",
            " Top 19 features, Selected Feature = 2,  Accuracy: 95.07783543365456\n",
            " Top 20 features, Selected Feature = 1,  Accuracy: 95.25389177168273\n",
            " Top 21 features, Selected Feature = 0,  Accuracy: 95.25389177168273\n",
            " Top 22 features, Selected Feature = 11,  Accuracy: 95.25389177168273\n",
            " Top 23 features, Selected Feature = 6,  Accuracy: 95.0784531751915\n",
            " Top 24 features, Selected Feature = 10,  Accuracy: 95.0784531751915\n",
            " Top 25 features, Selected Feature = 5,  Accuracy: 94.90177909562638\n",
            " Top 26 features, Selected Feature = 27,  Accuracy: 94.90177909562638\n",
            " Top 27 features, Selected Feature = 24,  Accuracy: 94.72634049913516\n",
            " Top 28 features, Selected Feature = 16,  Accuracy: 94.90177909562638\n",
            " Top 29 features, Selected Feature = 15,  Accuracy: 94.90177909562638\n",
            " Top 30 features, Selected Feature = 29,  Accuracy: 95.07783543365456\n",
            "time cost = 0.3944272994995117 seconds\n",
            " [-] Best Accuracy: 95.78267852730417\n",
            " [-] Selected Features for Best Accuracy: [19 14 17  9  4  7 18 25 26 28 20 12 21]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CJ2xR3e1wGmm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}